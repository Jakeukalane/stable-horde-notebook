{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aqualxx/stable-horde-notebook/blob/main/stable_horde.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # Use Google Drive (optional)\n",
        "#@markdown Models will be saved and loaded from your Google Drive.\n",
        "from google.colab import drive\n",
        "mount_google_drive = True\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "3qk09L_2q6J6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "9Yrgnqzk2Wou"
      },
      "outputs": [],
      "source": [
        "#@markdown # Download repo\n",
        "update_repo = False #@param {type:\"boolean\"}\n",
        "\n",
        "if not \"mount_google_drive\" in locals():\n",
        "  mount_google_drive = False\n",
        "\n",
        "if mount_google_drive:\n",
        "  %cd /content/gdrive/MyDrive/\n",
        "else:\n",
        "  %cd /content/\n",
        "\n",
        "if update_repo:\n",
        "  %cd nataili/\n",
        "  !git pull\n",
        "else:\n",
        "  !git clone https://github.com/Sygil-Dev/nataili.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # Install Python 3.8\n",
        "!sudo apt-get update -y\n",
        "!sudo apt-get install python3.8\n",
        "\n",
        "#change alternatives\n",
        "!sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.7 1\n",
        "!sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.8 2\n",
        "\n",
        "#check python version\n",
        "!python --version\n",
        "\n",
        "# Install pip\n",
        "!sudo apt install python3-pip\n",
        "!python -m pip install --upgrade pip"
      ],
      "metadata": {
        "cellView": "form",
        "id": "U9H99XmOZ6Qu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # Install dependencies\n",
        "\n",
        "if not \"mount_google_drive\" in locals():\n",
        "  mount_google_drive = False\n",
        "\n",
        "if mount_google_drive:\n",
        "  %cd /content/gdrive/MyDrive/nataili/\n",
        "else:\n",
        "  %cd /content/nataili\n",
        "\n",
        "!pip install -e .\n",
        "\n",
        "!pip install ray\n",
        "\n",
        "# See: https://github.com/CompVis/taming-transformers/issues/176\n",
        "# do not uncomment -e git+https://github.com/CompVis/taming-transformers.git@master#egg=taming-transformers\n",
        "!pip install invisible-watermark==0.1.5\n",
        "!pip install taming-transformers-rom1504==0.0.6  # required by ldm\n",
        "\n",
        "!pip install git+https://github.com/crowsonkb/k-diffusion.git\n",
        "\n",
        "# Dependencies required for Stable Diffusion UI\n",
        "!pip install pynvml==11.4.1\n",
        "!pip install omegaconf==2.2.3\n",
        "\n",
        "# Note: Jinja2 3.x major version required due to breaking changes found in markupsafe==2.1.1; 2.0.1 is incompatible with other upstream dependencies\n",
        "# see https://github.com/pallets/markupsafe/issues/304\n",
        "!pip install Jinja2==3.1.2  # Jinja2 is required by Gradio\n",
        "\n",
        "#!pip install diffusers==0.4.1\n",
        "!pip install diffusers==0.6.0\n",
        "\n",
        "# Img2text\n",
        "!pip install fairscale==0.4.4\n",
        "!pip install timm==0.6.7\n",
        "!pip install tqdm==4.64.0\n",
        "\n",
        "# Other\n",
        "!pip install retry==0.9.2  # used by sd_utils\n",
        "!pip install python-slugify==6.1.2  # used by sd_utils\n",
        "!pip install piexif==1.1.3  # used by sd_utils\n",
        "\n",
        "!pip install accelerate==0.12.0\n",
        "!pip install albumentations==0.4.3\n",
        "!pip install einops==0.3.1\n",
        "!pip install facexlib>=0.2.3\n",
        "!pip install imageio-ffmpeg==0.4.2\n",
        "!pip install imageio==2.9.0\n",
        "!pip install kornia==0.6\n",
        "!pip install loguru\n",
        "!pip install opencv-python-headless==4.6.0.66\n",
        "!pip install open-clip-torch==2.0.2\n",
        "!pip install pandas==1.4.3\n",
        "!pip install pudb==2019.2\n",
        "!pip install pytorch-lightning==1.7.7\n",
        "!pip install realesrgan==0.3.0\n",
        "!pip install test-tube>=0.7.5\n",
        "!pip install timm==0.6.7\n",
        "!pip install torch-fidelity==0.3.0\n",
        "#do not change transformers version\n",
        "!pip install transformers==4.21.3 # do not change\n",
        "#do not change transformers version\n",
        "!pip install wget\n",
        "\n",
        "# Upscalers\n",
        "!pip install basicsr==1.4.2  # required by RealESRGAN\n",
        "!pip install gfpgan==1.3.8  # GFPGAN\n",
        "!pip install realesrgan==0.3.0  # RealESRGAN brings in GFPGAN as a requirement\n",
        "!pip install git+https://github.com/CompVis/latent-diffusion\n",
        "\n",
        "## for monocular depth estimation \n",
        "!pip install tensorflow==2.10.0"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Dk7dKkA3bKWM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # Install xformers\n",
        "!wget https://github.com/pamparamm/xfromers_builds_colab/releases/download/3372350813/xformers-0.0.14.dev0-cp38-cp38-linux_x86_64.whl\n",
        "!pip install xformers-0.0.14.dev0-cp38-cp38-linux_x86_64.whl"
      ],
      "metadata": {
        "cellView": "form",
        "id": "OVm3aXJE9znC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setting worker info\n",
        "1. Rename `bridgeData_template.py` to `bridgeData.py`. \n",
        "2. Edit `bridgeData.py` and enter details such as the `horde_name` and `horde_api_key` you've received, so that you can receive Kudos.\n",
        "3. If you downloaded extra models other than 1.5, list it in `models_to_load`.\n",
        "\n",
        "OR\n",
        "\n",
        "1. Fill and run the cells bellow.\n",
        "\n",
        "**Note**: If you do not do this step, you will contribute anonymously."
      ],
      "metadata": {
        "id": "L4IfSgUTeNHJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # List available models (for models_to_load)\n",
        "if not \"mount_google_drive\" in locals():\n",
        "  mount_google_drive = False\n",
        "\n",
        "if mount_google_drive:\n",
        "  %cd /content/gdrive/MyDrive/nataili/\n",
        "else:\n",
        "  %cd /content/nataili\n",
        "\n",
        "import requests, json\n",
        "\n",
        "models = json.load(open(\"./db.json\"))\n",
        "\n",
        "try:\n",
        "    r = requests.get(\"https://raw.githubusercontent.com/Sygil-Dev/nataili-model-reference/main/db.json\")\n",
        "    models = r.json()\n",
        "except Exception:\n",
        "    models = json.load(open(\"./db.json\"))\n",
        "\n",
        "filtered_models = {}\n",
        "for model_name in models:\n",
        "  if models[model_name].get(\"type\") == \"ckpt\":\n",
        "    filtered_models[model_name] = models[model_name]\n",
        "\n",
        "ppmodels = \"\"\n",
        "for model_name in filtered_models:\n",
        "    if model_name == \"LDSR\":\n",
        "        continue\n",
        "    ppmodels += model_name\n",
        "    if filtered_models[model_name].get(\"description\"):\n",
        "        ppmodels += f\" : {filtered_models[model_name].get('description')}\"\n",
        "    ppmodels += \"\\n\"\n",
        "print(f\"## Known ckpt Models ##\\n{ppmodels}\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "yEl59-5wjzIL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The horde url\n",
        "horde_url = \"https://stablehorde.net\"\n",
        "# Give a cool name to your instance\n",
        "worker_name = \"My Awesome Instance\"\n",
        "# The api_key identifies a unique user in the horde\n",
        "# Visit https://stablehorde.net/register to create one before you can join\n",
        "api_key = \"0000000000\"\n",
        "# Put other users whose prompts you want to prioritize.\n",
        "# The owner's username is always included so you don't need to add it here,\n",
        "# unless you want it to have lower priority than another user\n",
        "priority_usernames = []\n",
        "# The amount of power your system can handle\n",
        "# 8 means 512*512. Each increase increases the possible resoluion by 64 pixes\n",
        "# So if you put this to 2 (the minimum, your SD can only generate 64x64 pixels\n",
        "# If you put this to 32, it is equivalent to 1024x1024 pixels\n",
        "max_power = 8\n",
        "# The amount of parallel jobs to pick up for the horde. Each running job will consume the amount of RAM needed to run each model, and will also affect the speed of other running jobs\n",
        "# so make sure you have enough VRAM to load models in parallel, and that the speed of fulfilling requests is not too slow\n",
        "# Expected limit per VRAM size: <6 VMAM: 1, <=8 VRAM: 2, <=12 VRAM:3, <=14 VRAM: 4\n",
        "# But remember that the speed of your gens will also be affected for each parallel job\n",
        "max_threads = 1\n",
        "# Set this to false, if you do not want your worker to receive requests for NSFW generations\n",
        "nsfw = True\n",
        "# Set this to True if you want your worker to censor NSFW generations. This will only be active is horde_nsfw == False\n",
        "censor_nsfw = False\n",
        "# A list of words which you do not want to your worker to accept\n",
        "blacklist = []\n",
        "# A list of words for which you always want to allow the NSFW censor filter, even when this worker is in NSFW mode\n",
        "censorlist = []\n",
        "# If set to False, this worker will no longer pick img2img jobs\n",
        "allow_img2img = True\n",
        "# If set to True, this worker will can pick inpainting jobs\n",
        "allow_painting = True\n",
        "# If set to False, this worker will no longer pick img2img jobs from unsafe IPs\n",
        "allow_unsafe_ip = True\n",
        "# The models to use. You can select a different main model, or select more than one.\n",
        "# With you can easily load 5 of these models with 32Gb RAM and 6G VRAM.\n",
        "# Adjust how many models you load based on how much RAM (not VRAM) you have available.\n",
        "# The last model in this list takes priority when the client accepts more than 1\n",
        "# if you do not know which models you can add here, use the below command\n",
        "# python show_available_models.py\n",
       "models_to_load = [\n",
        "    ## Generalist:\n",
	"    \"stable_diffusion\",  # This is the standard compvis model. It is not using Diffusers (yet)\n",
	"    # \"stable_diffusion_2.0\", # Dont use this yet. It is not implemented and will fail \n",
        "    # \"Midjourney Diffusion\", # Similar to Midjourney v4 images generations\n",
	"    # \"Midjourney PaintArt\", # Midjourney v4 painting style\n",      
	"\n",
        "    ## Enable this to allow inpainting/outpainting.\n",
	"    # \"stable_diffusion_inpainting\",\n",
	"\n",
	"    ## Generalist-merged:\n",
        "    # \"Mega Merge Diffusion\", # SD 1.5 merged with 17 other models \n",
	"    # \"Nitro Diffusion\", # Multi-Style model trained on Arcane, Archer and Mo-Di \n",
	"    # \"Samdoesarts Ultmerge\", # Portraits in the style of Sam Yang, merged with chewtoy and orange code-s models \n",
	"\n",
        "    ## 3D\n",
        "    # \"Clazy\", # Generates clay-like figures \n",
        "    # \"Microworlds\", # Isometric microworlds \n",
        "    # \"Papercut Diffusion\", # Paper cut images \n",
        "    # \"Redshift Diffusion\", # high resolution 3D artworks \n",        
        "    # \"Voxel Art Diffusion\", # Voxel art style generations \n",
	"\n",
        "    ## Animation-Anime-Cartoon-Manga:\n",
        "    # \"Anything Diffusion\", # Highly detailed Anime styled generations \n",
        "    # \"Classic Animation Diffusion\", # Popular animation studio classic style generations \n",
        "    # \"Comic-Diffusion\", # Western Comic book style \n",
        "    # \"Cyberpunk Anime Diffusion\", # Cyberpunk anime characters \n",
        "    # \"Furry Epoch\", # Furry styled generations \n",
        "    # \"Ghibli Diffusion\", # Studio Ghibli feature films style \n",
      	"    # \"Hentai Diffusion\", # NSFW: Anime focused model with better hands, obscure poses/camera angles and consistent style \n",
        "    # \"mo-di-diffusion\", # Popular animation studio modern style generations \n",
      	"    # \"Ranma Diffusion\", # Imitates the style of late 80s early 90-s anime, Anything v3 base \n",
	"    # \"Spider-Verse Diffusion\", # Based on the Into the Spider-Verse movie's animation style \n",
        "    # \"trinart\", # Manga styled generations \n",	
        "    # \"Yiffy\", # Furry styled generations \n",		
        "    # \"Zack3D\", # NSFW: Kink oriented furry styled generations \n",
        "    # \"waifu_diffusion\", # Anime styled generations \n",
	"\n",
        "    ## Fandom styles:\n",
        "    # \"Arcane Diffusion\", # Arcane TV show \n",
        "    # \"Archer Diffusion\", # Archer-s TV show animation style \n",
        "    # \"Borderlands\", # Borderlands video game style \n",
        "    # \"Dungeons and Diffusion\", # Generates DnD styled characters, trained on art commissions \n",
        "    # \"Elden Ring Diffusion\", # Based on the Elden Ring video game style \n",
        "    # \"Tron Legacy Diffusion\", # Tron Legacy movie style \n",
	"    # \"Xynthii-Diffusion\", # Xynthii: cyclops monster girls  \n",
	"\n",
        "    ## Painting styles\n",
	"    # \"AIO Pixel Art\", #Stable Diffusion fine tuned on pixel art sprites and scenes \n",
        "    # \"BubblyDubbly\", # Dreamy sketched-painted portraits \n",
        "    # \"colorbook\", # Minimalist coloring book style generations \n",
      	"    # \"Guohua Diffusion\", # Traditional Chinese paintings generations \n",
        "    # \"Van Gogh Diffusion\", # film Loving Vincent, best results with k_euler sampler \n",
	"    # \"vectorartz\", # Generate beautiful vector illustration \n",
	"\n",
        "    ## Others\n",
        "    # \"App Icon Diffusion\", # Mobile app icons \n",
	"    # \"Fantasy Card Diffusion\", # fantasy trading card style art, trained on all currently available Magic: the Gathering card art \n",
	"    # \"Inkpunk Diffusion\", #inspired by Gorillaz art, FLCL and Yoji Shinkawa. Trained on images generated from Midjourney \n",
        "    # \"JWST Deep Space Diffusion\", # James Webb Space Telescope imagery \n",
	"    # \"Knollingcase\", # generates a glass display case with objects inside, inspired by Sean Preston. Trained on Midjourney images \n",
        "    # \"Robo-Diffusion\", # Robot oriented drawing style \n",
	"    # \"Synthwave\", # Synthwave-outrun style \n",
        "    # \"Zeipher Female Model\", # NSFW: For creating images of nude solo women. Also known as f222 \n",
        "]"
      ],
      "metadata": {
        "id": "LfULY3uOREQq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # Start Stable Horde worker\n",
        "import os\n",
        "\n",
        "huggingface_token = \"\" #@param {type:\"string\"}\n",
        "\n",
        "if not \"mount_google_drive\" in locals():\n",
        "  mount_google_drive = False\n",
        "\n",
        "if mount_google_drive:\n",
        "  %cd /content/gdrive/MyDrive/nataili/\n",
        "else:\n",
        "  %cd /content/nataili/\n",
        "\n",
        "if \"api_key\" in locals():\n",
        "  data = f\"\"\"# The horde url\n",
        "horde_url = \"{horde_url}\"\n",
        "# Give a cool name to your instance\n",
        "worker_name = \"{worker_name}\"\n",
        "# The api_key identifies a unique user in the horde\n",
        "# Visit https://stablehorde.net/register to create one before you can join\n",
        "api_key = \"{api_key}\"\n",
        "# Put other users whose prompts you want to prioritize.\n",
        "# The owner's username is always included so you don't need to add it here, unless you want it to have lower priority than another user\n",
        "priority_usernames = {priority_usernames}\n",
        "# The amount of power your system can handle\n",
        "# 8 means 512*512. Each increase increases the possible resoluion by 64 pixes\n",
        "# So if you put this to 2 (the minimum, your SD can only generate 64x64 pixels\n",
        "# If you put this to 32, it is equivalent to 1024x1024 pixels\n",
        "max_power = {max_power}\n",
        "# The amount of parallel jobs to pick up for the horde. Each running job will consume the amount of RAM needed to run each model, and will also affect the speed of other running jobs\n",
        "# so make sure you have enough VRAM to load models in parallel, and that the speed of fulfilling requests is not too slow\n",
        "# Expected limit per VRAM size: <6 VMAM: 1, <=8 VRAM: 2, <=12 VRAM:3, <=14 VRAM: 4\n",
        "# But remember that the speed of your gens will also be affected for each parallel job\n",
        "max_threads = {max_threads}\n",
        "# Set this to false, if you do not want your worker to receive requests for NSFW generations\n",
        "nsfw = {nsfw}\n",
        "# Set this to True if you want your worker to censor NSFW generations. This will only be active is horde_nsfw == False\n",
        "censor_nsfw = {censor_nsfw}\n",
        "# A list of words which you do not want to your worker to accept\n",
        "blacklist = {blacklist}\n",
        "# A list of words for which you always want to allow the NSFW censor filter, even when this worker is in NSFW mode\n",
        "censorlist = {censorlist}\n",
        "# If set to False, this worker will no longer pick img2img jobs\n",
        "allow_img2img = {allow_img2img}\n",
        "# If set to True, this worker will can pick inpainting jobs\n",
        "allow_painting = {allow_painting}\n",
        "# If set to False, this worker will no longer pick img2img jobs from unsafe IPs\n",
        "allow_unsafe_ip = {allow_unsafe_ip}\n",
        "# The models to use. You can select a different main model, or select more than one.\n",
        "# With you can easily load 5 of these models with 32Gb RAM and 6G VRAM. Adjust how many models you load based on how much RAM (not VRAM) you have available\n",
        "# The last model in this list takes priority when the client accepts more than 1\n",
        "# if you do not know which models you can add here, use the below command\n",
        "# python show_available_models.py\n",
        "models_to_load = {models_to_load}\n",
        "  \"\"\"\n",
        "  toExec = \"\"\"text_file = open(\"bridgeData.py\", \"w+\"); text_file.write(data); text_file.close()\"\"\" \n",
        "  exec(toExec)\n",
        "\n",
        "!python bridge.py  --disable_voodoo --hf_token $huggingface_token"
      ],
      "metadata": {
        "cellView": "form",
        "id": "MUosNcNE3TPy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
